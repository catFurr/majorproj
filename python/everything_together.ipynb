{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from mnist import MNIST\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               100352    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1280      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,632\n",
      "Trainable params: 101,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2640 - accuracy: 0.9243\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1149 - accuracy: 0.9660\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0780 - accuracy: 0.9766\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0587 - accuracy: 0.9824\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0459 - accuracy: 0.9853\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0357 - accuracy: 0.9891\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0277 - accuracy: 0.9917\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0234 - accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0184 - accuracy: 0.9945\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0162 - accuracy: 0.9951\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.0865 - accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08647597581148148, 0.9764999747276306]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, use_bias=False, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, use_bias=False, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading dataset image (16x16)\n",
    "# img = cv2.imread('1.png', 0)\n",
    "mndata = MNIST('mnist')\n",
    "\n",
    "# images, labels = mndata.load_training()\n",
    "def get_rand_train():\n",
    "    index = random.randrange(0, len(images))  # choose an index ;-)\n",
    "    print(mndata.display(images[index]))\n",
    "    imgflat = images[index]\n",
    "    imgflat = [float(i)/255.0 for i in imgflat] # normalize the array\n",
    "    img = np.reshape(imgflat, (28, 28))\n",
    "\n",
    "    #defining time frame of 1s with steps of 5ms\n",
    "    T = 1;\n",
    "    dt = 0.005\n",
    "    time  = np.arange(0, T+dt, dt)\n",
    "    num_steps = round(T / dt) # 200\n",
    "    img_width = len(img) # 28\n",
    "    if img_width != len(img[0]): print(\"Error! Image is not square\") # we assume height and width are equal\n",
    "\n",
    "    #initializing spike train\n",
    "    base_train = np.zeros((img_width, img_width, num_steps))\n",
    "    uni_train = np.copy(base_train)\n",
    "    poisson_train = np.copy(base_train)\n",
    "    poisson_isi_train = np.copy(base_train)\n",
    "    uni_isi = -1\n",
    "    poisson_isi_isi = -1\n",
    "    for i in range(img_width):\n",
    "        for j in range(img_width):\n",
    "            pixel_value = img[i][j]\n",
    "            if pixel_value != 0:\n",
    "                uni_isi = 1 / pixel_value\n",
    "                poisson_isi_isi = np.ceil(-np.log(random.random())/pixel_value)\n",
    "            for k in range(num_steps):\n",
    "                if k % uni_isi == 0:\n",
    "                    uni_train[i][j][k] = 1\n",
    "                if random.random() < 1 * pixel_value: # c = 1\n",
    "                    poisson_train[i][j][k] = 1\n",
    "                if k % poisson_isi_isi == 0:\n",
    "                    poisson_isi_train[i][j][k] = 1\n",
    "    return uni_train, poisson_train, poisson_isi_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron:\n",
    "    def __init__(self, min_pot, thresh, leak, weight_arr):\n",
    "        self.min_pot = min_pot\n",
    "        self.thresh = thresh\n",
    "        self.leak = leak\n",
    "        self.weight_arr = weight_arr\n",
    "        self.reset()\n",
    "    \n",
    "    def step(self, input_arr):\n",
    "        ret_val = 0\n",
    "        k = sum([s*self.weight_arr[j] for j, s in enumerate(input_arr)])\n",
    "        self.pot = self.pot + k + self.leak\n",
    "        if self.pot >= self.thresh:\n",
    "            ret_val = self.thresh\n",
    "            self.pot = self.pot - self.thresh\n",
    "        if self.pot < self.min_pot:\n",
    "            self.pot = self.min_pot\n",
    "        return ret_val\n",
    "    \n",
    "    def reset(self):\n",
    "        self.pot = self.min_pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, weight_array2d, min_pot, thresh, leak):\n",
    "        self.neuron_arr = []\n",
    "        for i in range(len(weight_array2d)):\n",
    "            self.neuron_arr.append(neuron(min_pot, thresh, leak, weight_array2d[i]))\n",
    "    \n",
    "    def step(self, input_arr):\n",
    "        output_arr = np.zeros((len(self.neuron_arr)))\n",
    "        for i in range(len(output_arr)):\n",
    "            output_arr[i] = self.neuron_arr[i].step(input_arr)\n",
    "        return output_arr\n",
    "    \n",
    "    def reset(self):\n",
    "        for n in self.neuron_arr:\n",
    "            n.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_potential = 0\n",
    "threshold_potential = 0.5\n",
    "leakage = 0\n",
    "\n",
    "# layer 1 (input layer)\n",
    "# The spike train itself behaves as the input layer\n",
    "\n",
    "# layer 2\n",
    "weights_arr = np.zeros((128, 784))\n",
    "for i in range(len(weights_arr)):\n",
    "    for j in range(784):\n",
    "        weights_arr[i][j] = model.layers[1].weights[0][j][i]\n",
    "for i in range(len(weights_arr)):\n",
    "    weights_arr[i] = [(float(m)/np.max(weights_arr))/2 for m in weights_arr[i]]\n",
    "layer2 = layer(weights_arr, minimum_potential, threshold_potential, leakage)\n",
    "\n",
    "# layer 3 (output layer)\n",
    "weights_arr = np.zeros((10, 128))\n",
    "for i in range(len(weights_arr)):\n",
    "    for j in range(128):\n",
    "        weights_arr[i][j] = -model.layers[2].weights[0][j][i]\n",
    "for i in range(len(weights_arr)):\n",
    "    weights_arr[i] = [(float(m)/np.max(weights_arr))/2 for m in weights_arr[i]]\n",
    "layer3 = layer(weights_arr, minimum_potential, threshold_potential, leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining time frame of 1s with steps of 5ms\n",
    "T = 1;\n",
    "dt = 0.005\n",
    "time  = np.arange(0, T+dt, dt)\n",
    "num_steps = round(T / dt) # 200\n",
    "\n",
    "def run_train(train):\n",
    "    spike_train = np.array(train).reshape(784, num_steps)\n",
    "    # spike_train = np.array(poisson_train).reshape(784, num_steps)\n",
    "    # spike_train = np.array(poisson_isi_train).reshape(784, num_steps)\n",
    "\n",
    "    # run the model on the given spike train\n",
    "    output = np.zeros((10))\n",
    "    layer2.reset()\n",
    "    layer3.reset()\n",
    "    for i in range(num_steps):\n",
    "        m_input = np.zeros(784)\n",
    "        for j in range(784):\n",
    "            m_input[j] = spike_train[j][i]\n",
    "        out_layer2 = layer2.step(m_input)\n",
    "        out_layer3 = layer3.step(out_layer2)\n",
    "        for j in range(10):\n",
    "            output[j] = output[j] + out_layer3[j]\n",
    "        print(output)\n",
    "    print(\"Output Array: \", output)\n",
    "    print(\"Max value for: \", np.argmax(output)+1)\n",
    "    print(\"Expected output: \", labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............@@@@@@@@........\n",
      "...........@@@@@@@@@@@......\n",
      "..........@@@@....@@@@@.....\n",
      ".........@@@@@.......@@@....\n",
      ".......@@@@...........@@@...\n",
      ".......@@@............@@@...\n",
      "......@@@.............@@....\n",
      ".....@@@.............@@@....\n",
      ".....@@@............@@@.....\n",
      ".....@@@............@@......\n",
      ".....@@@...........@@@......\n",
      ".....@@@..........@@@.......\n",
      ".....@@@@.....@@@@@.........\n",
      "......@@@@@@@@@@@@..........\n",
      ".......@@@@@@@@@@...........\n",
      ".........@@@................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "[0.5 0.  0.  0.  0.5 0.  0.5 0.  0.5 0.5]\n",
      "[1.  0.5 0.  0.  1.  0.  0.5 0.5 1.  1. ]\n",
      "[1.5 1.  0.  0.  1.5 0.  0.5 1.  1.5 1.5]\n",
      "[2.  1.5 0.  0.  2.  0.5 0.5 1.5 2.  2. ]\n",
      "[2.5 2.  0.  0.  2.5 0.5 0.5 2.  2.5 2.5]\n",
      "[3.  2.5 0.  0.  3.  0.5 0.5 2.5 3.  3. ]\n",
      "[3.5 3.  0.  0.  3.5 1.  0.5 3.  3.5 3.5]\n",
      "[4.  3.5 0.  0.  4.  1.5 0.5 3.5 4.  4. ]\n",
      "[4.5 4.  0.  0.  4.5 1.5 0.5 4.  4.5 4.5]\n",
      "[5.  4.5 0.  0.  5.  2.  0.5 4.5 5.  5. ]\n",
      "[5.5 5.  0.  0.  5.5 2.  0.5 5.  5.5 5.5]\n",
      "[6.  5.5 0.  0.  6.  2.5 0.5 5.5 6.  6. ]\n",
      "[6.5 6.  0.  0.  6.5 2.5 0.5 6.  6.5 6.5]\n",
      "[7.  6.5 0.  0.  7.  3.  0.5 6.5 7.  7. ]\n",
      "[7.5 7.  0.  0.  7.5 3.5 0.5 7.  7.5 7.5]\n",
      "[8.  7.  0.  0.  8.  3.5 0.5 7.5 8.  8. ]\n",
      "[8.5 7.5 0.  0.  8.5 4.  0.5 8.  8.5 8.5]\n",
      "[9.  8.  0.  0.  9.  4.  0.5 8.5 9.  9. ]\n",
      "[9.5 8.5 0.  0.  9.5 4.  0.5 9.  9.5 9.5]\n",
      "[10.   9.   0.   0.  10.   4.5  0.5  9.5 10.  10. ]\n",
      "[10.5  9.5  0.   0.  10.5  4.5  0.5 10.  10.5 10.5]\n",
      "[11.  10.   0.   0.  11.   5.   0.5 10.5 11.  11. ]\n",
      "[11.5 10.5  0.   0.  11.5  5.   0.5 11.  11.5 11.5]\n",
      "[12.  11.   0.   0.  12.   5.5  0.5 11.5 12.  12. ]\n",
      "[12.5 11.5  0.   0.  12.5  5.5  0.5 12.  12.5 12.5]\n",
      "[13.  12.   0.   0.  13.   6.   0.5 12.5 13.  13. ]\n",
      "[13.5 12.5  0.   0.  13.5  6.   0.5 13.  13.5 13.5]\n",
      "[14.  13.   0.   0.  14.   6.5  0.5 13.5 14.  14. ]\n",
      "[14.5 13.5  0.   0.  14.5  7.   0.5 14.  14.5 14.5]\n",
      "[15.  14.   0.   0.  15.   7.   0.5 14.5 15.  15. ]\n",
      "[15.5 14.5  0.   0.  15.5  7.5  0.5 15.  15.5 15.5]\n",
      "[16.  15.   0.   0.  16.   7.5  0.5 15.5 16.  16. ]\n",
      "[16.5 15.   0.   0.  16.5  8.   0.5 16.  16.5 16.5]\n",
      "[17.  15.5  0.   0.  17.   8.   0.5 16.5 17.  17. ]\n",
      "[17.5 16.   0.   0.  17.5  8.5  0.5 17.  17.5 17.5]\n",
      "[18.  16.5  0.   0.  18.   8.5  0.5 17.5 18.  18. ]\n",
      "[18.5 17.   0.   0.  18.5  8.5  0.5 18.  18.5 18.5]\n",
      "[19.  17.5  0.   0.  19.   9.   0.5 18.5 19.  19. ]\n",
      "[19.5 18.   0.   0.  19.5  9.   0.5 19.  19.5 19.5]\n",
      "[20.  18.5  0.   0.  20.   9.5  0.5 19.5 20.  20. ]\n",
      "[20.5 19.   0.   0.  20.5 10.   0.5 20.  20.5 20.5]\n",
      "[21.  19.5  0.   0.  21.  10.   0.5 20.5 21.  21. ]\n",
      "[21.5 20.   0.   0.  21.5 10.5  0.5 21.  21.5 21.5]\n",
      "[22.  20.5  0.   0.  22.  10.5  0.5 21.5 22.  22. ]\n",
      "[22.5 21.   0.   0.  22.5 11.   0.5 22.  22.5 22.5]\n",
      "[23.  21.5  0.   0.  23.  11.   0.5 22.5 23.  23. ]\n",
      "[23.5 22.   0.   0.  23.5 11.5  0.5 23.  23.5 23.5]\n",
      "[24.  22.   0.   0.  24.  11.5  0.5 23.5 24.  24. ]\n",
      "[24.5 22.5  0.   0.  24.5 12.   0.5 24.  24.5 24.5]\n",
      "[25.  23.   0.   0.  25.  12.5  0.5 24.5 25.  25. ]\n",
      "[25.5 23.5  0.   0.  25.5 12.5  0.5 25.  25.5 25.5]\n",
      "[26.  24.   0.   0.  26.  13.   0.5 25.5 26.  26. ]\n",
      "[26.5 24.5  0.   0.  26.5 13.   0.5 26.  26.5 26.5]\n",
      "[27.  25.   0.   0.  27.  13.5  0.5 26.5 27.  27. ]\n",
      "[27.5 25.5  0.   0.  27.5 13.5  0.5 27.  27.5 27.5]\n",
      "[28.  26.   0.   0.  28.  14.   0.5 27.5 28.  28. ]\n",
      "[28.5 26.5  0.   0.  28.5 14.   0.5 28.  28.5 28.5]\n",
      "[29.  27.   0.   0.  29.  14.5  0.5 28.5 29.  29. ]\n",
      "[29.5 27.5  0.   0.  29.5 15.   0.5 29.  29.5 29.5]\n",
      "[30.  28.   0.   0.  30.  15.   0.5 29.5 30.  30. ]\n",
      "[30.5 28.5  0.   0.  30.5 15.5  0.5 30.  30.5 30.5]\n",
      "[31.  28.5  0.   0.  31.  15.5  0.5 30.5 31.  31. ]\n",
      "[31.5 29.   0.   0.  31.5 16.   0.5 31.  31.5 31.5]\n",
      "[32.  29.5  0.   0.  32.  16.   0.5 31.5 32.  32. ]\n",
      "[32.5 30.   0.   0.  32.5 16.5  0.5 32.  32.5 32.5]\n",
      "[33.  30.5  0.   0.  33.  16.5  0.5 32.5 33.  33. ]\n",
      "[33.5 31.   0.   0.  33.5 17.   0.5 33.  33.5 33.5]\n",
      "[34.  31.   0.   0.  34.  17.   0.5 33.5 34.  34. ]\n",
      "[34.5 31.5  0.   0.  34.5 17.5  0.5 34.  34.5 34.5]\n",
      "[35.  32.   0.   0.  35.  17.5  0.5 34.5 35.  35. ]\n",
      "[35.5 32.5  0.   0.  35.5 18.   0.5 35.  35.5 35.5]\n",
      "[36.  33.   0.   0.  36.  18.   0.5 35.5 36.  36. ]\n",
      "[36.5 33.5  0.   0.  36.5 18.5  0.5 36.  36.5 36.5]\n",
      "[37.  34.   0.   0.  37.  18.5  0.5 36.5 37.  37. ]\n",
      "[37.5 34.5  0.   0.  37.5 19.   0.5 37.  37.5 37.5]\n",
      "[38.  35.   0.   0.  38.  19.   0.5 37.5 38.  38. ]\n",
      "[38.5 35.5  0.   0.  38.5 19.5  0.5 38.  38.5 38.5]\n",
      "[39.  36.   0.   0.  39.  19.5  0.5 38.5 39.  39. ]\n",
      "[39.5 36.5  0.   0.  39.5 20.   0.5 39.  39.5 39.5]\n",
      "[40.  37.   0.   0.  40.  20.   0.5 39.5 40.  40. ]\n",
      "[40.5 37.5  0.   0.  40.5 20.5  0.5 40.  40.5 40.5]\n",
      "[41.  38.   0.   0.  41.  21.   0.5 40.5 41.  41. ]\n",
      "[41.5 38.5  0.   0.  41.5 21.   0.5 41.  41.5 41.5]\n",
      "[42.  38.5  0.   0.  42.  21.5  0.5 41.5 42.  42. ]\n",
      "[42.5 39.   0.   0.  42.5 21.5  0.5 42.  42.5 42.5]\n",
      "[43.  39.5  0.   0.  43.  22.   0.5 42.5 43.  43. ]\n",
      "[43.5 40.   0.   0.  43.5 22.   0.5 43.  43.5 43.5]\n",
      "[44.  40.5  0.   0.  44.  22.5  0.5 43.5 44.  44. ]\n",
      "[44.5 41.   0.   0.  44.5 22.5  0.5 44.  44.5 44.5]\n",
      "[45.  41.5  0.   0.  45.  23.   0.5 44.5 45.  45. ]\n",
      "[45.5 42.   0.   0.  45.5 23.   0.5 45.  45.5 45.5]\n",
      "[46.  42.5  0.   0.  46.  23.5  0.5 45.5 46.  46. ]\n",
      "[46.5 43.   0.   0.  46.5 23.5  0.5 46.  46.5 46.5]\n",
      "[47.  43.5  0.   0.  47.  24.   0.5 46.5 47.  47. ]\n",
      "[47.5 44.   0.   0.  47.5 24.   0.5 47.  47.5 47.5]\n",
      "[48.  44.5  0.   0.  48.  24.5  0.5 47.5 48.  48. ]\n",
      "[48.5 45.   0.   0.  48.5 24.5  0.5 48.  48.5 48.5]\n",
      "[49.  45.5  0.   0.  49.  25.   0.5 48.5 49.  49. ]\n",
      "[49.5 46.   0.   0.  49.5 25.5  0.5 49.  49.5 49.5]\n",
      "[50.  46.5  0.   0.  50.  25.5  0.5 49.5 50.  50. ]\n",
      "[50.5 46.5  0.   0.  50.5 26.   0.5 50.  50.5 50.5]\n",
      "[51.  47.   0.   0.  51.  26.   0.5 50.5 51.  51. ]\n",
      "[51.5 47.5  0.   0.  51.5 26.5  0.5 51.  51.5 51.5]\n",
      "[52.  48.   0.   0.  52.  26.5  0.5 51.5 52.  52. ]\n",
      "[52.5 48.5  0.   0.  52.5 27.   0.5 52.  52.5 52.5]\n",
      "[53.  49.   0.   0.  53.  27.   0.5 52.5 53.  53. ]\n",
      "[53.5 49.5  0.   0.  53.5 27.5  0.5 53.  53.5 53.5]\n",
      "[54.  50.   0.   0.  54.  27.5  0.5 53.5 54.  54. ]\n",
      "[54.5 50.5  0.   0.  54.5 28.   0.5 54.  54.5 54.5]\n",
      "[55.  51.   0.   0.  55.  28.5  0.5 54.5 55.  55. ]\n",
      "[55.5 51.5  0.   0.  55.5 28.5  0.5 55.  55.5 55.5]\n",
      "[56.  52.   0.   0.  56.  29.   0.5 55.5 56.  56. ]\n",
      "[56.5 52.5  0.   0.  56.5 29.   0.5 56.  56.5 56.5]\n",
      "[57.  53.   0.   0.  57.  29.5  0.5 56.5 57.  57. ]\n",
      "[57.5 53.   0.   0.  57.5 29.5  0.5 57.  57.5 57.5]\n",
      "[58.  53.5  0.   0.  58.  30.   0.5 57.5 58.  58. ]\n",
      "[58.5 54.   0.   0.  58.5 30.5  0.5 58.  58.5 58.5]\n",
      "[59.  54.5  0.   0.  59.  30.5  0.5 58.5 59.  59. ]\n",
      "[59.5 55.   0.   0.  59.5 31.   0.5 59.  59.5 59.5]\n",
      "[60.  55.5  0.   0.  60.  31.   0.5 59.5 60.  60. ]\n",
      "[60.5 56.   0.   0.  60.5 31.   0.5 60.  60.5 60.5]\n",
      "[61.  56.5  0.   0.  61.  31.5  0.5 60.5 61.  61. ]\n",
      "[61.5 57.   0.   0.  61.5 31.5  0.5 61.  61.5 61.5]\n",
      "[62.  57.5  0.   0.  62.  32.   0.5 61.5 62.  62. ]\n",
      "[62.5 58.   0.   0.  62.5 32.   0.5 62.  62.5 62.5]\n",
      "[63.  58.5  0.   0.  63.  32.5  0.5 62.5 63.  63. ]\n",
      "[63.5 59.   0.   0.  63.5 32.5  0.5 63.  63.5 63.5]\n",
      "[64.  59.5  0.   0.  64.  33.   0.5 63.5 64.  64. ]\n",
      "[64.5 60.   0.   0.  64.5 33.5  0.5 64.  64.5 64.5]\n",
      "[65.  60.5  0.   0.  65.  33.5  0.5 64.5 65.  65. ]\n",
      "[65.5 60.5  0.   0.  65.5 34.   0.5 65.  65.5 65.5]\n",
      "[66.  61.   0.   0.  66.  34.   0.5 65.5 66.  66. ]\n",
      "[66.5 61.5  0.   0.  66.5 34.5  0.5 66.  66.5 66.5]\n",
      "[67.  62.   0.   0.  67.  34.5  0.5 66.5 67.  67. ]\n",
      "[67.5 62.5  0.   0.  67.5 35.   0.5 67.  67.5 67.5]\n",
      "[68.  62.5  0.   0.  68.  35.   0.5 67.5 68.  68. ]\n",
      "[68.5 63.   0.   0.  68.5 35.5  0.5 68.  68.5 68.5]\n",
      "[69.  63.5  0.   0.  69.  35.5  0.5 68.5 69.  69. ]\n",
      "[69.5 64.   0.   0.  69.5 36.   0.5 69.  69.5 69.5]\n",
      "[70.  64.5  0.   0.  70.  36.   0.5 69.5 70.  70. ]\n",
      "[70.5 65.   0.   0.  70.5 36.5  0.5 70.  70.5 70.5]\n",
      "[71.  65.5  0.   0.  71.  36.5  0.5 70.5 71.  71. ]\n",
      "[71.5 66.   0.   0.  71.5 37.   0.5 71.  71.5 71.5]\n",
      "[72.  66.5  0.   0.  72.  37.   0.5 71.5 72.  72. ]\n",
      "[72.5 67.   0.   0.  72.5 37.5  0.5 72.  72.5 72.5]\n",
      "[73.  67.5  0.   0.  73.  37.5  0.5 72.5 73.  73. ]\n",
      "[73.5 68.   0.   0.  73.5 38.   0.5 73.  73.5 73.5]\n",
      "[74.  68.5  0.   0.  74.  38.   0.5 73.5 74.  74. ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74.5 69.   0.   0.  74.5 38.5  0.5 74.  74.5 74.5]\n",
      "[75.  69.5  0.   0.  75.  39.   0.5 74.5 75.  75. ]\n",
      "[75.5 70.   0.   0.  75.5 39.   0.5 75.  75.5 75.5]\n",
      "[76.  70.5  0.   0.  76.  39.   0.5 75.5 76.  76. ]\n",
      "[76.5 70.5  0.   0.  76.5 39.5  0.5 76.  76.5 76.5]\n",
      "[77.  71.   0.   0.  77.  40.   0.5 76.5 77.  77. ]\n",
      "[77.5 71.5  0.   0.  77.5 40.   0.5 77.  77.5 77.5]\n",
      "[78.  72.   0.   0.  78.  40.   0.5 77.5 78.  78. ]\n",
      "[78.5 72.5  0.   0.  78.5 40.5  0.5 78.  78.5 78.5]\n",
      "[79.  73.   0.   0.  79.  41.   0.5 78.5 79.  79. ]\n",
      "[79.5 73.5  0.   0.  79.5 41.   0.5 79.  79.5 79.5]\n",
      "[80.  74.   0.   0.  80.  41.5  0.5 79.5 80.  80. ]\n",
      "[80.5 74.5  0.   0.  80.5 41.5  0.5 80.  80.5 80.5]\n",
      "[81.  75.   0.   0.  81.  42.   0.5 80.5 81.  81. ]\n",
      "[81.5 75.5  0.   0.  81.5 42.   0.5 81.  81.5 81.5]\n",
      "[82.  76.   0.   0.  82.  42.5  0.5 81.5 82.  82. ]\n",
      "[82.5 76.5  0.   0.  82.5 43.   0.5 82.  82.5 82.5]\n",
      "[83.  77.   0.   0.  83.  43.   0.5 82.5 83.  83. ]\n",
      "[83.5 77.5  0.   0.  83.5 43.5  0.5 83.  83.5 83.5]\n",
      "[84.  77.5  0.   0.  84.  43.5  0.5 83.5 84.  84. ]\n",
      "[84.5 78.   0.   0.  84.5 44.   0.5 84.  84.5 84.5]\n",
      "[85.  78.5  0.   0.  85.  44.   0.5 84.5 85.  85. ]\n",
      "[85.5 79.   0.   0.  85.5 44.5  0.5 85.  85.5 85.5]\n",
      "[86.  79.5  0.   0.  86.  44.5  0.5 85.5 86.  86. ]\n",
      "[86.5 80.   0.   0.  86.5 44.5  0.5 86.  86.5 86.5]\n",
      "[87.  80.5  0.   0.  87.  45.   0.5 86.5 87.  87. ]\n",
      "[87.5 81.   0.   0.  87.5 45.   0.5 87.  87.5 87.5]\n",
      "[88.  81.5  0.   0.  88.  45.5  0.5 87.5 88.  88. ]\n",
      "[88.5 82.   0.   0.  88.5 45.5  0.5 88.  88.5 88.5]\n",
      "[89.  82.5  0.   0.  89.  46.   0.5 88.5 89.  89. ]\n",
      "[89.5 83.   0.   0.  89.5 46.5  0.5 89.  89.5 89.5]\n",
      "[90.  83.5  0.   0.  90.  46.5  0.5 89.5 90.  90. ]\n",
      "[90.5 84.   0.   0.  90.5 47.   0.5 90.  90.5 90.5]\n",
      "[91.  84.5  0.   0.  91.  47.   0.5 90.5 91.  91. ]\n",
      "[91.5 84.5  0.   0.  91.5 47.5  0.5 91.  91.5 91.5]\n",
      "[92.  85.   0.   0.  92.  47.5  0.5 91.5 92.  92. ]\n",
      "[92.5 85.5  0.   0.  92.5 48.   0.5 92.  92.5 92.5]\n",
      "[93.  86.   0.   0.  93.  48.   0.5 92.5 93.  93. ]\n",
      "[93.5 86.5  0.   0.  93.5 48.5  0.5 93.  93.5 93.5]\n",
      "[94.  87.   0.   0.  94.  48.5  0.5 93.5 94.  94. ]\n",
      "[94.5 87.5  0.   0.  94.5 49.   0.5 94.  94.5 94.5]\n",
      "[95.  88.   0.   0.  95.  49.   0.5 94.5 95.  95. ]\n",
      "[95.5 88.5  0.   0.  95.5 49.5  0.5 95.  95.5 95.5]\n",
      "[96.  89.   0.   0.  96.  49.5  0.5 95.5 96.  96. ]\n",
      "[96.5 89.5  0.   0.  96.5 50.   0.5 96.  96.5 96.5]\n",
      "[97.  90.   0.   0.  97.  50.   0.5 96.5 97.  97. ]\n",
      "[97.5 90.5  0.   0.  97.5 50.5  0.5 97.  97.5 97.5]\n",
      "[98.  91.   0.   0.  98.  50.5  0.5 97.5 98.  98. ]\n",
      "[98.5 91.5  0.   0.  98.5 51.   0.5 98.  98.5 98.5]\n",
      "[99.  92.   0.   0.  99.  51.5  0.5 98.5 99.  99. ]\n",
      "[99.5 92.5  0.   0.  99.5 51.5  0.5 99.  99.5 99.5]\n",
      "[100.   93.    0.    0.  100.   52.    0.5  99.5 100.  100. ]\n",
      "Output Array:  [100.   93.    0.    0.  100.   52.    0.5  99.5 100.  100. ]\n",
      "Max value for:  1\n",
      "Expected output:  3\n"
     ]
    }
   ],
   "source": [
    "uni_t, poi_t, poi_isi_t = get_rand_train()\n",
    "run_train(uni_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(i > 0 for i in layer2.neuron_arr[0].weight_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.449569603201572"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sum(el.weight_arr[0:12]) for el in layer3.neuron_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6873327670763038"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(layer3.neuron_arr[3].weight_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
